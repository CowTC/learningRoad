1. 目的
	Scrapy中随机设定user-agent，防止被ban。

2. 版本号
	2.1) scrapy.__version__==1.1.1

3. 在弄明白scrapy框架的基础上，需要证明白修改user-agent需要修改哪部分。

	答案是修改download-middleware

	3.1 相应的方法添加在middlewares.py中
		
	#-*-coding:utf-8-*-  
	import random  
	from scrapy.downloadermiddlewares.useragent import UserAgentMiddleware  
  
	class RotateUserAgentMiddleware(UserAgentMiddleware):  
		def __init__(self, user_agent=''):  
			self.user_agent = user_agent  
  
		def process_request(self, request, spider):  
			#the default user_agent_list composes chrome,I E,firefox,Mozilla,opera,netscape  
			#for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php  
			user_agent_list= ["Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1",
				"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11", 
				"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6",
				"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6",
				"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1",
				"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5",
				"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5",
				"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
				"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
				"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3",
				"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3",
				"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24",
				"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"]  

			ua = random.choice(user_agent_list)  
			if ua:  
				print ua, '!!!---yyyyyyyyyy---eeeeeeeeee---ssssssssss---!!!'  
				request.headers.setdefault('User-Agent', ua)  

	3.2 修改setting文件中的download-middleware，激活相应的方法。

4. scrapy==1.1.1中setting中设定单个USER_AGENT，是最直接有效的方法。

	4.1 在进行zhihu.com的爬取过程中，必须设定USER_AGENT；

	4.2 单个添加middleware.py是行不通的，还需要进一步探测机制；

	4.3 在探测机制过程中，我想打印当前request的headers，一直没打印成功。
